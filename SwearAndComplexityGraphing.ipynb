{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis\n",
    "\n",
    "Out of the scraped lyrics data, we ended up with approximately 420 good points since a significant number of entries had a zero complexity score. This was mostly due to instrumental songs being scraped or missing lyrics. After cleaning up the data, we began to explore its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfd = pd.read_csv(\"cleaned_lyrics_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCount and Complexity/Swear Ratio Analysis\n",
    "\n",
    "The first subject of interest is frequency of occurence for words across all collected lyrics. In order to get a meaningful wordcount of words specific to technical death metal, we had to cut out commonly occuring stop words from our counting. This was done by using the stopwords list from https://algs4.cs.princeton.edu/35applications/stopwords.txt and adding a few words of our own that were appearing and were clearly not informative. We then plotted both the relationship between our complexity metric and swear words ratio as well as the top 10 most commonly occurring words to get initial introspection into our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "stopwords_file = open(\"stopwords.txt\")\n",
    "stopwords = []\n",
    "for word in stopwords_file:\n",
    "    stopwords.append(word.strip())\n",
    "stopwords_file.close()\n",
    "    \n",
    "stopwords.append('i')\n",
    "stopwords.append('')\n",
    "stopwords.append('-')\n",
    "\n",
    "def word_count():\n",
    "    wordcount = {}\n",
    "    for lyrics in dfd[\"lyrics\"]:\n",
    "        parsed = str(lyrics).split(\" \")\n",
    "        for word in parsed:\n",
    "            if word.lower() not in stopwords:\n",
    "                count = wordcount.get(word.lower(), 0)\n",
    "                wordcount[word.lower()] = count + 1\n",
    "    return wordcount\n",
    "\n",
    "wordcount = sorted(word_count().items(), key=operator.itemgetter(1), reverse = True)\n",
    "wcx, wcy = zip(*wordcount[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make an interactive graph of our two preliminary explorations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"d6de954a-3df6-4a3d-a784-f7fcac0d4039\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"d6de954a-3df6-4a3d-a784-f7fcac0d4039\");\n",
       "      el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"d6de954a-3df6-4a3d-a784-f7fcac0d4039\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'd6de954a-3df6-4a3d-a784-f7fcac0d4039' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"d6de954a-3df6-4a3d-a784-f7fcac0d4039\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"d6de954a-3df6-4a3d-a784-f7fcac0d4039\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2474af943abb4b4b96337ca6cf305fe0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update1>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.palettes import Spectral10, RdYlBu10, PiYG10\n",
    "from ipywidgets import interact\n",
    "output_notebook()\n",
    "\n",
    "s = figure(plot_height = 800, plot_width = 800, title = \"Complexity vs. Swear Words Ratio\")\n",
    "s.circle(\"complexity\", \"swear_words_ratio\", source = dfd)\n",
    "s.xaxis.axis_label = \"Lyrical Complexity\"\n",
    "s.yaxis.axis_label = \"Swear Words Ratio\"\n",
    "\n",
    "v = figure(plot_height = 800, plot_width = 800, x_range = list(wcx), title = \"Top 10 Words by Appearence\")\n",
    "v.vbar(wcx, 0.5, wcy, color = RdYlBu10)\n",
    "\n",
    "def update1(Graph):\n",
    "    if Graph == \"Complexity vs. Swear Words\":\n",
    "        show(s, notebook_handle = True)\n",
    "    if Graph == \"Most Common Words\":\n",
    "        show(v, notebook_handle = True)        \n",
    "    push_notebook()\n",
    "\n",
    "interact(update1, Graph=['Complexity vs. Swear Words', 'Most Common Words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 1 Analysis:\n",
    "\n",
    "Based on our plots, we see that the distribution of data is relatively random and it's difficult to make a statement directly relating lyrical complexity and the ratio of swear words. It seems as though there is an ever so slight slight positive correlation between complexity and swear words at the far end of the data set, but the data also becomes much more sparse and variable. Within the center cluster of data set, there is no clear pattern between swear words ratio and lyrical complexity. \n",
    "\n",
    "Out of the top 10 most commonly occurring words, there are no swear words. Most words follow themes of death and mortality, which we have colorfully illustrated with a bright color palette.\n",
    "\n",
    "# Highest Scoring Songs\n",
    "\n",
    "Of particular interest was to determine if there was any overlap between high scoring songs and high swear ratio songs. We thus plotted the top 10 most lyrically complex and highest swearing songs against together in an interactive plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8bf36e51f84c14985d75d6a6bb9a26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update2>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10comp = dfd.nlargest(10, \"complexity\")\n",
    "compx = top10comp[\"song\"]\n",
    "compy = top10comp[\"complexity\"]\n",
    "\n",
    "top10swears = dfd.nlargest(10, \"swear_words_ratio\")\n",
    "swearsx = top10swears[\"song\"]\n",
    "swearsy = top10swears[\"swear_words_ratio\"]\n",
    "\n",
    "t = figure(plot_height = 800, plot_width = 1500, x_range = list(top10comp[\"song\"]), title = \"Top 10 Complexity Scores by Song Name\")\n",
    "pbars = t.vbar(compx, 0.5, compy, color = Spectral10)\n",
    "q = figure(plot_height = 800, plot_width = 1500, x_range = list(top10swears[\"song\"]), title = \"Top 10 Swear Ratios Scores by Song Name\")\n",
    "qbars = q.vbar(swearsx, 0.5, swearsy, color = PiYG10)\n",
    "\n",
    "\n",
    "def update2(Graph):\n",
    "    if Graph == \"Complexity\":\n",
    "        show(t, notebook_handle = True)\n",
    "    if Graph == \"Swear Words Ratio\":\n",
    "        show(q, notebook_handle = True)        \n",
    "    push_notebook()\n",
    "\n",
    "interact(update2, Graph=['Complexity', 'Swear Words Ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 2 Analysis:\n",
    "\n",
    "Surprisingly, or unsurprisingly, it seems as though the songs that scored higher on the complexity metric had much tamer/thoughtful song titles compared to songs that scored higher on the swear words ratio metric. Lyrically complex songs tended to more poetically titled with a more philosophical predilection (\"The Resonant Frequency of Flesh\"). Songs with a high proportion of swear words were titled much more aggressively and carried a darker tone (\"Scum Fuck the Weak\", for example).\n",
    "\n",
    "# Band Names and Complexity:\n",
    "\n",
    "The last visualization we created attempted to observe the distribution in complexity between artists, which meant averaging the complexity scores of all their songs contained in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6f7a7e339240319d7f699f8fbe8d26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update3>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "combined = list(zip(dfd['artist'], dfd['complexity']))\n",
    "avgcomp = {}\n",
    "for item in combined:\n",
    "    avg = avgcomp.get(item[0], 0)\n",
    "    avgcomp[item[0]] = (avg + item[1])/2\n",
    "\n",
    "dfn = pd.DataFrame()\n",
    "dfn['bandname'] = list(avgcomp.keys())\n",
    "dfn['complexity'] = list(avgcomp.values())\n",
    "dfn['index'] = np.arange(len(dfn.index))\n",
    "\n",
    "r = figure(plot_height= 800, plot_width = 800, tools = [\"hover\"], title = \"Avg Complexity by Band (Hover for Details)\")\n",
    "r.circle('index', \"complexity\", size = 20, source = dfn, color = \"aquamarine\")\n",
    "\n",
    "r.select_one(HoverTool).tooltips = [\n",
    "    ('Band Name', '@bandname'),\n",
    "    ('Complexity', '@complexity')\n",
    "]\n",
    "\n",
    "combined2 = list(zip(dfd['artist'], dfd['swear_words_ratio']))\n",
    "avgcomp2 = {}\n",
    "for item in combined2:\n",
    "    avg = avgcomp2.get(item[0], 0)\n",
    "    avgcomp2[item[0]] = (avg + item[1])/2\n",
    "\n",
    "dfm = pd.DataFrame()\n",
    "dfm['bandname'] = list(avgcomp2.keys())\n",
    "dfm['swear_words_ratio'] = list(avgcomp2.values())\n",
    "dfm['index'] = np.arange(len(dfm.index))\n",
    "\n",
    "l = figure(plot_height= 800, plot_width = 800, tools = [\"hover\"], title = \"Avg Swearing by Band (Hover for Details)\")\n",
    "l.circle('index', \"swear_words_ratio\", size = 20, source = dfm, color = \"Navy\")\n",
    "\n",
    "l.select_one(HoverTool).tooltips = [\n",
    "    ('Band Name', '@bandname'),\n",
    "    ('Swear Words Ratio', '@swear_words_ratio')\n",
    "]\n",
    "\n",
    "def update3(Graph):\n",
    "    if Graph == \"Average Complexity By Band Name\":\n",
    "        show(r, notebook_handle = True)\n",
    "    if Graph == \"Average Swear Ratio By Band Name\":\n",
    "        show(l, notebook_handle = True)        \n",
    "    push_notebook()\n",
    "\n",
    "interact(update3, Graph=['Average Complexity By Band Name', 'Average Swear Ratio By Band Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 3 Analysis:\n",
    "\n",
    "From this scatter plot, we can see that bands with more literately complicated/poetic names such as \"Aeon\", \"Extol\", \"Arsis\" have relatively high lyrical complexity compared to most other bands with aggressive, less poetic sounding words such as \"Dying Fetus\", \"Decapitated\", \"Monstrosity\", and \"Aborted\". There also exist a number of wordy, poetic names such as \"Obscura\" and \"Nocturnus\" with average complexity scores similar to bands alongside these bands, but the only band with a non-poetic name is \"Death\", which is perhaps less aggressive than something like \"Aborted\". However, having high average lyrical complexity does not mean a low average swearing ratio. \"Extol\" maintains the highest swearing ratio despite also having one of the highest average complexity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
